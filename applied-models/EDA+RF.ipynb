{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EDA+RF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPcvI8APgJZSQWReY6w6PJb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linghduoduo/Machine_Learning/blob/master/EDA%2BRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsiuw0772zfr",
        "outputId": "902b6d7f-b763-4e9d-dd67-db0d1868d79d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id '1KSFIRh0-_Vr7SdiSCZP1ItV7bXPxMD92' --output data.tar.gz\n",
        "!tar -zxvf data.tar.gz\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KSFIRh0-_Vr7SdiSCZP1ItV7bXPxMD92\n",
            "To: /content/data.tar.gz\n",
            "6.11MB [00:00, 53.2MB/s]\n",
            "data/\n",
            "data/sample_submission.csv\n",
            "data/test_no_label.csv\n",
            "data/train.csv\n",
            "data/X_test\n",
            "data/X_train\n",
            "data/Y_train\n",
            "data  data.tar.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY-NbfJE6F4O"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "X_train_fpath = './data/X_train'\n",
        "Y_train_fpath = './data/Y_train'\n",
        "X_test_fpath = './data/X_test'\n",
        "output_fpath = './output_{}.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAlaj1QO6NH4"
      },
      "source": [
        "# Parse csv files to numpy array\n",
        "with open(X_train_fpath) as f:\n",
        "    next(f)\n",
        "    X_train = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)\n",
        "with open(Y_train_fpath) as f:\n",
        "    next(f)\n",
        "    Y_train = np.array([line.strip('\\n').split(',')[1] for line in f], dtype = float)\n",
        "with open(X_test_fpath) as f:\n",
        "    next(f)\n",
        "    X_test = np.array([line.strip('\\n').split(',')[1:] for line in f], dtype = float)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhqbNDdP6Ujv",
        "outputId": "d0d7330a-0309-439b-cd49-0b9c74952d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[33.,  1.,  0., ..., 52.,  0.,  1.],\n",
              "       [63.,  1.,  0., ..., 52.,  0.,  1.],\n",
              "       [71.,  0.,  0., ...,  0.,  0.,  1.],\n",
              "       ...,\n",
              "       [16.,  0.,  0., ...,  8.,  1.,  0.],\n",
              "       [48.,  1.,  0., ..., 52.,  0.,  1.],\n",
              "       [48.,  0.,  0., ...,  0.,  0.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21EX7X7r6gK9"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Vh4PlR6igc"
      },
      "source": [
        "train = pd.DataFrame(X_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6hdlCS-6xE6",
        "outputId": "5d862889-ed86-47cb-99ef-c7882535b181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 54256 entries, 0 to 54255\n",
            "Columns: 510 entries, 0 to 509\n",
            "dtypes: float64(510)\n",
            "memory usage: 211.1 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNHzaF16ASla"
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgIWYsEQAsA1",
        "outputId": "4ab5ddad-cfb2-4e3d-e03f-5d49102440e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "drive.mount('/gdrive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8-nCgt_Ar87",
        "outputId": "ae706953-522d-4a1d-ac0b-0cd29098bf12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file_path = glob.glob(\"/gdrive/My Drive/Interview/Company/Peacock/mxm.csv\")\n",
        "for file in file_path:    \n",
        "   df = pd.read_csv(file)    \n",
        "   print(df)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Unnamed: 0 Network  ... Minute_In_Commercial Total_Loss_perc\n",
            "0              0     DKN  ...                    0       15.637767\n",
            "1              1     DKN  ...                    0        5.965321\n",
            "2              2     DKN  ...                    0        6.501681\n",
            "3              3     DKN  ...                    0        5.259257\n",
            "4              4     DKN  ...                    0        3.366675\n",
            "...          ...     ...  ...                  ...             ...\n",
            "2083        2083     DKN  ...                    0        2.861576\n",
            "2084        2084     DKN  ...                    0        2.398557\n",
            "2085        2085     DKN  ...                    0        1.854381\n",
            "2086        2086     DKN  ...                    0        1.782612\n",
            "2087        2087     DKN  ...                    1        0.000000\n",
            "\n",
            "[2088 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXRdud07EZGv",
        "outputId": "385ae0a7-1900-4dd1-f8a6-2c8d93075e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2088 entries, 0 to 2087\n",
            "Data columns (total 9 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Unnamed: 0            2088 non-null   int64  \n",
            " 1   Network               2088 non-null   object \n",
            " 2   Date                  2088 non-null   object \n",
            " 3   Time                  2088 non-null   object \n",
            " 4   Program               2088 non-null   object \n",
            " 5   Length                2088 non-null   int64  \n",
            " 6   Rating                2088 non-null   float64\n",
            " 7   Minute_In_Commercial  2088 non-null   int64  \n",
            " 8   Total_Loss_perc       2088 non-null   float64\n",
            "dtypes: float64(2), int64(3), object(4)\n",
            "memory usage: 146.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDhzqAY4GlSi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnPXNUV6XjOq"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7okwGyumYORy",
        "outputId": "b1776c2f-cc7e-4c6e-c7cf-f1d9df4fd1ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import rankdata\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.cluster.hierarchy import cophenet\n",
        "from scipy.spatial.distance import squareform\n",
        "import fastcluster\n",
        "import networkx as nx\n",
        "from statsmodels.stats.correlation_tools import corr_nearest\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D7Zf3P7Yfdz"
      },
      "source": [
        "def compute_mst_stats(corr):\n",
        "    dist = (1 - corr) / 2\n",
        "    G = nx.from_numpy_matrix(dist)\n",
        "    mst = nx.minimum_spanning_tree(G)\n",
        "\n",
        "    features = pd.Series()\n",
        "    features['mst_avg_shortest'] = nx.average_shortest_path_length(mst)\n",
        "\n",
        "\n",
        "    closeness_centrality = (pd.Series(list(nx.closeness_centrality(mst).values()))\n",
        "                            .describe())\n",
        "    for stat in closeness_centrality.index[1:]:\n",
        "        features[f'mst_centrality_{stat}'] = closeness_centrality[stat]\n",
        "\n",
        "    return features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLkIfXaOYsD9"
      },
      "source": [
        "def compute_features_from_correl(model_corr):\n",
        "    n = model_corr.shape[0]\n",
        "    a, b = np.triu_indices(n, k=1)\n",
        "    \n",
        "    features = pd.Series()\n",
        "    coefficients = model_corr[a, b].flatten()\n",
        "\n",
        "    coeffs = pd.Series(coefficients)\n",
        "    coeffs_stats = coeffs.describe()\n",
        "    for stat in coeffs_stats.index[1:]:\n",
        "        features[f'coeffs_{stat}'] = coeffs_stats[stat]\n",
        "    features['coeffs_1%'] = coeffs.quantile(q=0.01)\n",
        "    features['coeffs_99%'] = coeffs.quantile(q=0.99)\n",
        "    features['coeffs_10%'] = coeffs.quantile(q=0.1)\n",
        "    features['coeffs_90%'] = coeffs.quantile(q=0.9)\n",
        "\n",
        "\n",
        "    # eigenvals\n",
        "    eigenvals, eigenvecs = np.linalg.eig(model_corr)\n",
        "    permutation = np.argsort(eigenvals)[::-1]\n",
        "    eigenvals = eigenvals[permutation]\n",
        "    eigenvecs = eigenvecs[:, permutation]\n",
        "\n",
        "    pf_vector = eigenvecs[:, np.argmax(eigenvals)]\n",
        "    if len(pf_vector[pf_vector < 0]) > len(pf_vector[pf_vector > 0]):\n",
        "        pf_vector = -pf_vector\n",
        "\n",
        "    features['varex_eig1'] = float(eigenvals[0] / sum(eigenvals))\n",
        "    features['varex_eig_top5'] = (float(sum(eigenvals[:5])) /\n",
        "                                  float(sum(eigenvals)))\n",
        "    features['varex_eig_top30'] = (float(sum(eigenvals[:30])) /\n",
        "                                   float(sum(eigenvals)))\n",
        "    # Marcenko-Pastur (RMT)\n",
        "    T, N = 252, n\n",
        "    MP_cutoff = (1 + np.sqrt(N / T))**2\n",
        "    # variance explained by eigenvals outside of the MP distribution\n",
        "    features['varex_eig_MP'] = (\n",
        "        float(sum([e for e in eigenvals if e > MP_cutoff])) /\n",
        "        float(sum(eigenvals)))\n",
        "    \n",
        "    # determinant\n",
        "    features['determinant'] = np.prod(eigenvals)\n",
        "    \n",
        "    # condition number\n",
        "    features['condition_number'] = abs(eigenvals[0]) / abs(eigenvals[-1])\n",
        "\n",
        "\n",
        "    # stats of the first eigenvector entries\n",
        "    pf_stats = pd.Series(pf_vector).describe()\n",
        "    if pf_stats['mean'] < 1e-5:\n",
        "        returnNone\n",
        "    for stat in pf_stats.index[1:]:\n",
        "        features[f'pf_{stat}'] = float(pf_stats[stat])\n",
        "\n",
        "\n",
        "    # stats on the MST\n",
        "    features = pd.concat([features, compute_mst_stats(model_corr)], axis=0)\n",
        "\n",
        "    # stats on the linkage\n",
        "    dist = np.sqrt(2 * (1 - model_corr))\n",
        "    for algo in ['ward', 'single', 'complete', 'average']:\n",
        "        Z = fastcluster.linkage(dist[a, b], method=algo)\n",
        "        features[f'coph_corr_{algo}'] = cophenet(Z, dist[a, b])[0]\n",
        "\n",
        "    return features.sort_index()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiRExTtiYzYS"
      },
      "source": [
        "def compute_dataset_features(mats):\n",
        "    all_features = []\n",
        "    for i in range(mats.shape[0]):\n",
        "        model_corr = mats[i, :, :]\n",
        "\n",
        "        features = compute_features_from_correl(model_corr)\n",
        "\n",
        "        if features is not None:\n",
        "            all_features.append(features)\n",
        "    \n",
        "    return pd.concat(all_features, axis=1).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKbr4pYrfbup"
      },
      "source": [
        "empirical_matrices = np.load('empirical_matrices.npy')\n",
        "\n",
        "empirical_features = compute_dataset_features(empirical_matrices)\n",
        "\n",
        "empirical_features.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBte8_oSfg_x"
      },
      "source": [
        "empirical_features.to_hdf('empirical_features.h5', key='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_J6UUMgftIL"
      },
      "source": [
        "plt.figure(figsize=(16, 32))\n",
        "for idx, col in enumerate(empirical_features.columns):\n",
        "    plt.subplot(9, 4, idx + 1)\n",
        "    qlow = empirical_features[col].quantile(0.01)\n",
        "    qhigh = empirical_features[col].quantile(0.99)\n",
        "    plt.hist(empirical_features[col]\n",
        "             .clip(lower=qlow, upper=qhigh)\n",
        "             .replace(qlow, np.nan)\n",
        "             .replace(qhigh, np.nan),\n",
        "             bins=100, log=False)\n",
        "    plt.axvline(x=empirical_features[col].mean(), color='r',\n",
        "                linestyle='dashed', linewidth=2)\n",
        "    plt.title(col)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccm60s4_ZgHw"
      },
      "source": [
        "n = len(empirical_features.columns)\n",
        "a, b = np.triu_indices(n, k=1)\n",
        "\n",
        "plt.figure(figsize=(18, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "corr_features = empirical_features.corr(method='spearman')\n",
        "dist = (1 - corr_features).values\n",
        "Z = fastcluster.linkage(dist[a, b], method='ward')\n",
        "permutation = hierarchy.leaves_list(\n",
        "    hierarchy.optimal_leaf_ordering(Z, dist[a, b]))\n",
        "\n",
        "sorted_corr_features = empirical_features[\n",
        "    empirical_features.columns[permutation]].corr(method='spearman')\n",
        "plt.pcolormesh(sorted_corr_features)\n",
        "plt.colorbar()\n",
        "plt.title(f'Correlation between the {n} features', fontsize=16)\n",
        "plt.subplot(1, 2, 2)\n",
        "corr_features = (empirical_features\n",
        "                 .corr(method='spearman')\n",
        "                 .abs())\n",
        "dist = (1 - corr_features).values\n",
        "Z = fastcluster.linkage(dist[a, b], method='ward')\n",
        "permutation = hierarchy.leaves_list(\n",
        "    hierarchy.optimal_leaf_ordering(Z, dist[a, b]))\n",
        "\n",
        "sorted_corr_features = (empirical_features[\n",
        "    empirical_features.columns[permutation]]\n",
        "                        .corr(method='spearman')\n",
        "                        .abs())\n",
        "plt.pcolormesh(sorted_corr_features)\n",
        "plt.colorbar()\n",
        "plt.title(f'Absolute correlation between the {n} features', fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsMj_1AxZ3js"
      },
      "source": [
        "nb_clusters = 4\n",
        "\n",
        "dist = 1 - sorted_corr_features.values\n",
        "dim = len(dist)\n",
        "tri_a, tri_b = np.triu_indices(dim, k=1)\n",
        "Z = fastcluster.linkage(dist[tri_a, tri_b], method='ward')\n",
        "clustering_inds = hierarchy.fcluster(Z, nb_clusters,\n",
        "                                     criterion='maxclust')\n",
        "clusters = {i: [] for i in range(min(clustering_inds),\n",
        "                                 max(clustering_inds) + 1)}\n",
        "for i, v in enumerate(clustering_inds):\n",
        "    clusters[v].append(i)\n",
        "    \n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.pcolormesh(sorted_corr_features)\n",
        "for cluster_id, cluster in clusters.items():\n",
        "    xmin, xmax = min(cluster), max(cluster)\n",
        "    ymin, ymax = min(cluster), max(cluster)\n",
        "    \n",
        "    plt.axvline(x=xmin,\n",
        "                ymin=ymin / dim, ymax=(ymax + 1) / dim,\n",
        "                color='r')\n",
        "    plt.axvline(x=xmax + 1,\n",
        "                ymin=ymin / dim, ymax=(ymax + 1) / dim,\n",
        "                color='r')\n",
        "    plt.axhline(y=ymin,\n",
        "                xmin=xmin / dim, xmax=(xmax + 1) / dim,\n",
        "                color='r')\n",
        "    plt.axhline(y=ymax + 1,\n",
        "                xmin=xmin / dim, xmax=(xmax + 1) / dim,\n",
        "                color='r')\n",
        "plt.show()\n",
        "\n",
        "for i, cluster in enumerate(clusters):\n",
        "    print('Cluster', i + 1)\n",
        "    cluster_members = [sorted_corr_features.index[ind]\n",
        "                       for ind in clusters[cluster]]\n",
        "    print('Cluster size:', len(cluster_members))\n",
        "    pprint(cluster_members)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcfAxsskaFji"
      },
      "source": [
        "pairs = [('varex_eig1', 'varex_eig_top5'),\n",
        "         ('varex_eig_MP', 'varex_eig_top5'),\n",
        "         ('varex_eig_top5', 'varex_eig_top30'),\n",
        "         ('pf_std', 'varex_eig_top5'),\n",
        "         ('pf_std', 'pf_mean'),\n",
        "         ('mst_centrality_mean', 'mst_centrality_std'),\n",
        "         ('mst_avg_shortest', 'mst_centrality_25%'),\n",
        "         ('mst_avg_shortest', 'mst_centrality_mean'),\n",
        "         ('mst_avg_shortest', 'pf_max'),\n",
        "         ('determinant', 'varex_eig_top30'),\n",
        "         ('determinant', 'pf_std'),\n",
        "         ('determinant', 'pf_mean'),\n",
        "         ('coph_corr_single', 'pf_mean'),\n",
        "         ('coph_corr_single', 'pf_std'),\n",
        "         ('coph_corr_single', 'varex_eig_top5'),\n",
        "         ('coph_corr_average', 'coph_corr_complete'),\n",
        "         ('coph_corr_average', 'coph_corr_single'),\n",
        "         ('coph_corr_average', 'coph_corr_ward'),\n",
        "         ('coph_corr_average', 'pf_25%'),\n",
        "         ('coph_corr_average', 'pf_75%'),\n",
        "         ('coph_corr_average', 'pf_std'),\n",
        "         ('coph_corr_average', 'pf_mean'),\n",
        "         ('coph_corr_average', 'varex_eig1'),\n",
        "         ('condition_number', 'determinant'),\n",
        "         ('condition_number', 'mst_avg_shortest'),\n",
        "         ('condition_number', 'mst_centrality_25%'),\n",
        "         ('condition_number', 'pf_mean'),\n",
        "         ('condition_number', 'varex_eig1'),\n",
        "         ('coeffs_std', 'coph_corr_average'),\n",
        "         ('coeffs_std', 'coph_corr_single'),\n",
        "         ('coeffs_std', 'determinant'),\n",
        "         ('coeffs_std', 'pf_25%'),\n",
        "         ('coeffs_std', 'pf_75%'),\n",
        "         ('coeffs_std', 'pf_std'),\n",
        "         ('coeffs_mean', 'varex_eig1'),\n",
        "         ('coeffs_90%', 'determinant'),\n",
        "         ('coeffs_10%', 'coeffs_25%'),\n",
        "         ('coeffs_25%', 'coeffs_50%'),\n",
        "         ('coeffs_50%', 'coeffs_75%'),\n",
        "         ('coeffs_75%', 'coeffs_90%'),\n",
        "         ('coeffs_10%', 'coeffs_90%'),\n",
        "         ('coeffs_50%', 'coeffs_std'),\n",
        "         ('coeffs_50%', 'pf_mean'),\n",
        "         ('coeffs_50%', 'pf_std'),\n",
        "         ('coeffs_75%', 'coph_corr_complete'),\n",
        "         ('coeffs_75%', 'coph_corr_ward'),\n",
        "         ('coeffs_75%', 'pf_mean'),\n",
        "         ('coeffs_1%', 'coph_corr_average'),\n",
        "         ('coeffs_1%', 'coph_corr_complete'),\n",
        "         ('coeffs_1%', 'coph_corr_single'),\n",
        "         ('coeffs_1%', 'coph_corr_ward'),\n",
        "         ('coeffs_1%', 'pf_25%'),\n",
        "         ('coeffs_1%', 'pf_75%'),\n",
        "         ('coeffs_1%', 'pf_std'),\n",
        "         ('coeffs_1%', 'pf_mean'),\n",
        "         ('coeffs_1%', 'coeffs_min'),]\n",
        "\n",
        "plt.figure(figsize=(18, 66))\n",
        "for idx, (var1, var2) in enumerate(pairs):\n",
        "    plt.subplot(14, 4, idx + 1)\n",
        "    rk1 = rankdata(empirical_features[var1])\n",
        "    rk1 /= len(rk1)\n",
        "    rk2 = rankdata(empirical_features[var2])\n",
        "    rk2 /= len(rk2)\n",
        "    plt.hist2d(rk1, rk2, bins=40)\n",
        "    plt.xlabel(var1, fontsize=16)\n",
        "    plt.ylabel(var2, fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60rGPojPc-if"
      },
      "source": [
        "pairs = [('varex_eig1', 'varex_eig_top5'),\n",
        "\n",
        "from multiprocessing import Pool\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.cluster.hierarchy import cophenet\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import fastcluster\n",
        "import networkx as nx\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PBGLbb5f1qc"
      },
      "source": [
        "pairs = [('varex_eig1', 'varex_eig_top5'),\n",
        "\n",
        "from multiprocessing import Pool\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.cluster import hierarchy\n",
        "from scipy.cluster.hierarchy import cophenet\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import fastcluster\n",
        "import networkx as nx\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aIQc171f_P1"
      },
      "source": [
        "def compute_dataset_features(mats):\n",
        "    all_features = []\n",
        "    for i in range(mats.shape[0]):\n",
        "        model_corr = mats[i, :, :]\n",
        "\n",
        "        features = compute_features_from_correl(model_corr)\n",
        "\n",
        "        if features isnotNone:\n",
        "            all_features.append(features)\n",
        "    \n",
        "    return pd.concat(all_features, axis=1).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk_zCY9dgCg_"
      },
      "source": [
        "def compute_dataset_features__par(mats):\n",
        "    p = Pool(3)\n",
        "    all_features = p.imap(compute_features_from_correl,\n",
        "                          tqdm.tqdm([mats[i, :, :]\n",
        "                                     for i in range(mats.shape[0])]))\n",
        "    p.close()\n",
        "    p.join()\n",
        "    \n",
        "    return pd.concat(all_features, axis=1).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0_GMyjAgHQ2"
      },
      "source": [
        "regimes = ['stressed', 'normal', 'rally']\n",
        "regime_features = {}\n",
        "for regime in regimes:\n",
        "    corr_matrices = np.load(f'{regime}_matrices.npy')\n",
        "    \n",
        "    plt.figure(figsize=(16, 16))\n",
        "    for i in range(16):\n",
        "        corr = corr_matrices[i, :, :]\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.pcolormesh(corr)\n",
        "    plt.show()\n",
        "    \n",
        "    corr_features = compute_dataset_features__par(corr_matrices)\n",
        "\n",
        "    regime_features[regime] = corr_features.astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL4Ww4gBgMCj"
      },
      "source": [
        "for regime in regimes:\n",
        "    regime_features[regime].to_hdf(\n",
        "        f'regime_{regime}_features.h5', key='features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps_g4Z9HgTr4"
      },
      "source": [
        "regimes = ['stressed', 'normal', 'rally']\n",
        "regime_features = {}\n",
        "for regime in regimes:\n",
        "    regime_features[regime] = pd.read_hdf(f'regime_{regime}_features.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMicxkO7gWgf"
      },
      "source": [
        "colors = ['r', 'b', 'g']\n",
        "plt.figure(figsize=(16, 40))\n",
        "for idx, col in enumerate(regime_features['stressed'].columns):\n",
        "    plt.subplot(12, 4, idx + 1)\n",
        "    for ic, regime in enumerate(['stressed', 'normal', 'rally']):\n",
        "        qlow = regime_features[regime][col].quantile(0.01)\n",
        "        qhigh = regime_features[regime][col].quantile(0.99)\n",
        "        plt.hist(regime_features[regime][col]\n",
        "                 .clip(lower=qlow, upper=qhigh)\n",
        "                 .replace(qlow, np.nan)\n",
        "                 .replace(qhigh, np.nan),\n",
        "                 bins=100, log=False, color=colors[ic], alpha=0.5)\n",
        "        plt.axvline(x=regime_features[regime][col].mean(), color=colors[ic],\n",
        "                    linestyle='dashed', linewidth=2)\n",
        "    plt.title(col)\n",
        "    plt.legend(regimes)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erVxG2eCgn49"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MllrRK_6g4Qk"
      },
      "source": [
        "用Scikit-Learn做一个基本的随机森林，而无需任何（微调）调整"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-ssJ-9ig_6O"
      },
      "source": [
        "for regime in regimes:\n",
        "    regime_features[regime]['target'] = regime\n",
        "\n",
        "data = pd.concat([regime_features[regime] for regime in regimes], axis=0)\n",
        "data = data.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSJn2GGvhDUk"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.loc[:, data.columns != 'target'], data['target'],\n",
        "    test_size=0.2, random_state=13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbc83xluhG8U"
      },
      "source": [
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print('Accuracy on train set:', clf.score(X_train, y_train))\n",
        "print('Accuracy on test set:', clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfKqeRTShJqG"
      },
      "source": [
        "labels = ['stressed', 'normal', 'rally']\n",
        "confusion_mat = confusion_matrix(\n",
        "    y_test, clf.predict(X_test), labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gOSV-wphMeu"
      },
      "source": [
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    import itertools\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "\n",
        "    if cmap isNone:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names isnotNone:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "    thresh = cm.max() / 1.5if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\"if cm[i, j] > thresh else\"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\"if cm[i, j] > thresh else\"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.2f}'.format(accuracy))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoSCXxaFhTa6"
      },
      "source": [
        "plot_confusion_matrix(confusion_mat, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbH7J7uthagM"
      },
      "source": [
        "proba = clf.predict_proba(X_test)\n",
        "\n",
        "labels = ['normal', 'rally', 'stressed']\n",
        "plt.figure(figsize=(18, 5))\n",
        "for id_class, cls in enumerate(labels):\n",
        "    plt.subplot(1, 3, id_class + 1)\n",
        "    x = proba[proba.argmax(axis=1) == id_class]\n",
        "    print(f'Number of {cls} data-points:\\t {x.shape[0]}')\n",
        "    plt.bar(labels, x.mean(axis=0),\n",
        "        color=['blue', 'green', 'red'])\n",
        "    plt.title(\n",
        "        f'Average classifier confidence given class = {cls}')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyrAhK_Zhezp"
      },
      "source": [
        "proba = clf.predict_proba(X_test)\n",
        "\n",
        "labels = ['normal', 'rally', 'stressed']\n",
        "str2int = {s: idc for idc, s in enumerate(labels)}\n",
        "plt.figure(figsize=(18, 5))\n",
        "for id_class, cls in enumerate(labels):\n",
        "    plt.subplot(1, 3, id_class + 1)\n",
        "    majority_class = proba.argmax(axis=1) == id_class\n",
        "    correct_class = (proba.argmax(axis=1) ==\n",
        "                     [str2int[y] for y in y_test])\n",
        "    x = proba[majority_class & correct_class]\n",
        "    print(f'Number of {cls} data-points:\\t {x.shape[0]}')\n",
        "    plt.bar(labels, x.mean(axis=0),\n",
        "        color=['blue', 'green', 'red'])\n",
        "    plt.title(\n",
        "        f'Average confidence given class = {cls} & correct')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0iJtguzhkE_"
      },
      "source": [
        "def get_high_confidence(X, y):\n",
        "    pred = clf.predict_proba(X)\n",
        "    high_confidence_features = X.iloc[pred.max(axis=1) > 0.90]\n",
        "    high_confidence_labels = y.iloc[pred.max(axis=1) > 0.90]\n",
        "    \n",
        "    return high_confidence_features, high_confidence_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6cWzj5YhrX6"
      },
      "source": [
        "def get_high_confidence(X, y):\n",
        "    pred = cfeatures_train, labels_train = get_high_confidence(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9ckGj4lhuqS"
      },
      "source": [
        "labels_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97CpE7O8hxWb"
      },
      "source": [
        "features_test, labels_test = get_high_confidence(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y9cSM6Vh0pB"
      },
      "source": [
        "labels_test.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0961wjlch4YW"
      },
      "source": [
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print('Accuracy on test set:', round(clf.score(X_test, y_test), 2))\n",
        "print('Accuracy on test set when model has high confidence:',\n",
        "      round(clf.score(features_test, labels_test), 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fkqbLcOh8Ec"
      },
      "source": [
        "def display_shap_importance(X, X_high_confidence, sample_type='train'):\n",
        "    height = 10\n",
        "    width = 20\n",
        "    plt.figure(figsize=(height, width))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    # shap on the whole dataset\n",
        "    explainer = shap.TreeExplainer(clf)\n",
        "    shap_values = explainer.shap_values(X, approximate=True)\n",
        "    shap.summary_plot(shap_values, X,\n",
        "                      plot_type=\"bar\",\n",
        "                      class_names=['normal', 'rally', 'stressed'],\n",
        "                      plot_size=(width, height), show=False)\n",
        "    plt.title(f'Whole {sample_type} dataset', fontsize=18)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    # shap on the high confidence dataset\n",
        "    explainer = shap.TreeExplainer(clf)\n",
        "    shap_values = explainer.shap_values(X_high_confidence, approximate=True)\n",
        "    shap.summary_plot(shap_values, X_high_confidence,\n",
        "                      plot_type=\"bar\",\n",
        "                      class_names=['normal', 'rally', 'stressed'],\n",
        "                      plot_size=(width, height), show=False)\n",
        "    plt.title(f'High confidence predictions on {sample_type} dataset',\n",
        "    fontsize=18)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC5eneaWiAv9"
      },
      "source": [
        "display_shap_importance(X_train, features_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDgGD3HjiDbr"
      },
      "source": [
        "display_shap_importance(X_test, features_test, sample_type='test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsfu8WK4iGDz"
      },
      "source": [
        "def display_shap_per_class(X, sample_type='train'):\n",
        "    explainer = shap.TreeExplainer(clf)\n",
        "    shap_values = explainer.shap_values(X, approximate=True)\n",
        "    \n",
        "    height = 12\n",
        "    width = 20\n",
        "    plt.figure(figsize=(height, width))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    shap.summary_plot(shap_values[2], X,\n",
        "                      color_bar=False,\n",
        "                      plot_size=(width, height),\n",
        "                      show=False)\n",
        "    plt.title(f'Stressed regime -- {sample_type}', fontsize=18)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    shap.summary_plot(shap_values[1], X,\n",
        "                      color_bar=False,\n",
        "                      plot_size=(width, height),\n",
        "                      show=False)\n",
        "    plt.title(f'Rally regime -- {sample_type}', fontsize=18)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    shap.summary_plot(shap_values[0], X,\n",
        "                      color_bar=True,\n",
        "                      plot_size=(width, height),\n",
        "                      show=False)\n",
        "    plt.title(f'Normal regime -- {sample_type}', fontsize=18)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8WK3TmxiN4e"
      },
      "source": [
        "display_shap_per_class(X_train)\n",
        "display_shap_per_class(features_train, sample_type='hc train')\n",
        "display_shap_per_class(X_test, sample_type='test')\n",
        "display_shap_per_class(features_test, sample_type='hc test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGq15mLriSOk"
      },
      "source": [
        "feat1 = 'varex_eig_MP'\n",
        "feat2 = 'coph_corr_single'\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train[[feat1, feat2]], y_train)\n",
        "\n",
        "features_train, labels_train = get_high_confidence(\n",
        "    X_train[[feat1, feat2]], y_train)\n",
        "features_test, labels_test = get_high_confidence(\n",
        "    X_test[[feat1, feat2]], y_test)\n",
        "\n",
        "print('Accuracy on the train set: \\t',\n",
        "      round(clf.score(X_train[[feat1, feat2]], y_train), 2))\n",
        "print('Accuracy on the train set when the model has high confidence: \\t',\n",
        "      round(clf.score(features_train[[feat1, feat2]], labels_train), 2))\n",
        "print('Accuracy on the test set: \\t',\n",
        "      round(clf.score(X_test[[feat1, feat2]], y_test), 2))\n",
        "print('Accuracy on the test set when the model has high confidence: \\t',\n",
        "      round(clf.score(features_test[[feat1, feat2]], labels_test), 2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMkmFE_UigWk"
      },
      "source": [
        "def plot_feat2d(features, labels, feat1, feat2, fig_title='',\n",
        "                nr=2, nc=2, idx=1, disp_normal=True):\n",
        "    data = pd.concat([features, labels], axis=1)\n",
        "    plt.subplot(nr, nc, idx)\n",
        "    tg = 'stressed'\n",
        "    plt.scatter(data[data['target'] == tg][feat1],\n",
        "                data[data['target'] == tg][feat2],\n",
        "                alpha=0.2, label=tg, color='red')\n",
        "    tg = 'rally'\n",
        "    plt.scatter(data[data['target'] == tg][feat1],\n",
        "                data[data['target'] == tg][feat2],\n",
        "                alpha=0.2, label=tg, color='green')\n",
        "    if disp_normal:\n",
        "        tg = 'normal'\n",
        "        plt.scatter(data[data['target'] == tg][feat1],\n",
        "                    data[data['target'] == tg][feat2],\n",
        "                    alpha=0.2, label=tg, color='blue')\n",
        "    plt.xlabel(feat1)\n",
        "    plt.ylabel(feat2)\n",
        "    plt.legend()\n",
        "    plt.title(fig_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgL9PpMQikh7"
      },
      "source": [
        "plt.figure(figsize=(18, 12))\n",
        "plot_feat2d(X_train, y_train, feat1, feat2,\n",
        "            fig_title='Train dataset', idx=1, disp_normal=False)\n",
        "plot_feat2d(features_train, labels_train, feat1, feat2,\n",
        "            fig_title='Subset of Train dataset where model has high confidence',\n",
        "            idx=2, disp_normal=False)\n",
        "\n",
        "plot_feat2d(X_test, y_test, feat1, feat2,\n",
        "            fig_title='Test dataset', idx=3, disp_normal=False)\n",
        "plot_feat2d(features_test, labels_test, feat1, feat2,\n",
        "            fig_title='Subset of Test dataset where model has high confidence',\n",
        "            idx=4, disp_normal=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzfliRXwinJ-"
      },
      "source": [
        "plt.figure(figsize=(18, 12))\n",
        "plot_feat2d(X_train, y_train, feat1, feat2,\n",
        "            fig_title='Train dataset', idx=1)\n",
        "plot_feat2d(features_train, labels_train, feat1, feat2,\n",
        "            fig_title='Subset of Train dataset where model has high confidence',\n",
        "            idx=2)\n",
        "\n",
        "\n",
        "plot_feat2d(X_test, y_test, feat1, feat2,\n",
        "            fig_title='Test dataset', idx=3)\n",
        "plot_feat2d(features_test, labels_test, feat1, feat2,\n",
        "            fig_title='Subset of Test dataset where model has high confidence',\n",
        "            idx=4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaHGO-i9isEb"
      },
      "source": [
        "def plot_feat2d_proba_level(features, feat1, feat2,\n",
        "                            nr=2, nc=2, idx=1,\n",
        "                            fig_title=''):\n",
        "    proba = clf.predict_proba(features[[feat1, feat2]])\n",
        "    plt.subplot(nr, nc, idx)\n",
        "    cm = plt.cm.get_cmap('RdYlBu')\n",
        "    sc = plt.scatter(features[feat1],\n",
        "                     features[feat2],\n",
        "                     c=proba.max(axis=1),\n",
        "                     vmin=0,\n",
        "                     vmax=1,\n",
        "                     s=50,\n",
        "                     cmap=cm)\n",
        "    plt.colorbar(sc)\n",
        "    plt.xlabel(feat1)\n",
        "    plt.ylabel(feat2)\n",
        "    plt.title(fig_title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6TOS5TdixeY"
      },
      "source": [
        "plt.figure(figsize=(18, 12))\n",
        "plot_feat2d_proba_level(X_train, feat1, feat2, idx=1,\n",
        "    fig_title='Model confidence on Train dataset')\n",
        "plot_feat2d_proba_level(features_train, feat1, feat2, idx=2,\n",
        "    fig_title='Model confidence on High-Confidence-Train dataset')\n",
        "plot_feat2d_proba_level(X_test, feat1, feat2, idx=3,\n",
        "    fig_title='Model confidence on Test dataset')\n",
        "plot_feat2d_proba_level(features_test, feat1, feat2, idx=4,\n",
        "    fig_title='Model confidence on High-Confidence-Test dataset')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoUZzxN_i1b_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}